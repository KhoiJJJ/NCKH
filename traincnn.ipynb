{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_with_deltas(audio, sr=16000, n_mfcc=13):\n",
    "    \"\"\"\n",
    "    Extract MFCCs, delta, and delta-delta features from an audio signal.\n",
    "    \"\"\"\n",
    "    hop_length = int(0.01 * sr)  # 10 ms hop length\n",
    "    win_length = int(0.025 * sr)  # 25 ms window length\n",
    "    \n",
    "    # Calculate MFCCs (including the 0th coefficient)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, win_length=win_length, window='hamming')\n",
    "    \n",
    "    # Calculate log energy feature\n",
    "    # energy = np.log(np.sum(librosa.feature.rms(y=audio, hop_length=hop_length)**2, axis=0))\n",
    "    \n",
    "    # Append log energy as the 0th feature\n",
    "    # mfccs[0, :] = energy\n",
    "    \n",
    "    # Compute the deltas (first derivative)\n",
    "    mfcc_delta = librosa.feature.delta(mfccs)\n",
    "    \n",
    "    # Compute delta-delta (second derivative)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    # Stack MFCCs, delta, and delta-delta features\n",
    "    mfcc_combined = np.vstack([mfccs, mfcc_delta, mfcc_delta2])\n",
    "    \n",
    "    return mfcc_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from folders\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = os.listdir(data_dir)\n",
    "    \n",
    "    for label in labels:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for file_name in os.listdir(label_dir):\n",
    "            if file_name.endswith(\".wav\"):\n",
    "                file_path = os.path.join(label_dir, file_name)\n",
    "                # Load the audio file\n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                features = extract_mfcc_with_deltas(audio,sr)\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Load training and testing data\n",
    "train_data_dir = r'C:\\Users\\USER\\Downloads\\SV_NCKH_audio_event\\Train'\n",
    "test_data_dir = r'C:\\Users\\USER\\Downloads\\SV_NCKH_audio_event\\Test'\n",
    "\n",
    "X_train, y_train = load_data(train_data_dir)\n",
    "X_test, y_test = load_data(test_data_dir)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Reshape for CNN input (add channel dimension)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # 2D Convolution Layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Additional Conv Layers\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    # Create the Adam optimizer with the custom learning rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11776</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,507,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,709</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11776\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,507,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │         \u001b[38;5;34m2,709\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,528,981</span> (5.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,528,981\u001b[0m (5.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,528,981</span> (5.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,528,981\u001b[0m (5.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.1732 - loss: 6.3476 - val_accuracy: 0.4636 - val_loss: 1.7317\n",
      "Epoch 2/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.5811 - loss: 1.3573 - val_accuracy: 0.5254 - val_loss: 1.5903\n",
      "Epoch 3/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7071 - loss: 0.8831 - val_accuracy: 0.6173 - val_loss: 1.4292\n",
      "Epoch 4/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8009 - loss: 0.6289 - val_accuracy: 0.6118 - val_loss: 1.6379\n",
      "Epoch 5/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.8417 - loss: 0.4743 - val_accuracy: 0.6118 - val_loss: 1.9390\n",
      "Epoch 6/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.8941 - loss: 0.3354 - val_accuracy: 0.5898 - val_loss: 2.0057\n",
      "Epoch 7/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9144 - loss: 0.2458 - val_accuracy: 0.5789 - val_loss: 2.1293\n",
      "Epoch 8/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9547 - loss: 0.1479 - val_accuracy: 0.6310 - val_loss: 2.5182\n",
      "Epoch 9/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9541 - loss: 0.1395 - val_accuracy: 0.6228 - val_loss: 2.3424\n",
      "Epoch 10/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9901 - loss: 0.0528 - val_accuracy: 0.6159 - val_loss: 2.5929\n",
      "Epoch 11/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9879 - loss: 0.0445 - val_accuracy: 0.6173 - val_loss: 2.3238\n",
      "Epoch 12/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9859 - loss: 0.0550 - val_accuracy: 0.5693 - val_loss: 2.7901\n",
      "Epoch 13/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9683 - loss: 0.1110 - val_accuracy: 0.5638 - val_loss: 3.2120\n",
      "Epoch 14/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9703 - loss: 0.1037 - val_accuracy: 0.5487 - val_loss: 3.2932\n",
      "Epoch 15/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9712 - loss: 0.1040 - val_accuracy: 0.5418 - val_loss: 3.3107\n",
      "Epoch 16/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9859 - loss: 0.0624 - val_accuracy: 0.5981 - val_loss: 3.0826\n",
      "Epoch 17/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9919 - loss: 0.0283 - val_accuracy: 0.6063 - val_loss: 3.4563\n",
      "Epoch 18/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9983 - loss: 0.0094 - val_accuracy: 0.6132 - val_loss: 3.0957\n",
      "Epoch 19/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6159 - val_loss: 3.4339\n",
      "Epoch 20/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.6173 - val_loss: 3.4686\n",
      "Epoch 21/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 7.8383e-04 - val_accuracy: 0.6145 - val_loss: 3.5357\n",
      "Epoch 22/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 7.6398e-04 - val_accuracy: 0.6132 - val_loss: 3.5678\n",
      "Epoch 23/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.1814e-04 - val_accuracy: 0.6104 - val_loss: 3.6104\n",
      "Epoch 24/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 5.6696e-04 - val_accuracy: 0.6118 - val_loss: 3.6553\n",
      "Epoch 25/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 4.7963e-04 - val_accuracy: 0.6159 - val_loss: 3.6776\n",
      "Epoch 26/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 4.4314e-04 - val_accuracy: 0.6159 - val_loss: 3.7127\n",
      "Epoch 27/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.3106e-04 - val_accuracy: 0.6118 - val_loss: 3.7428\n",
      "Epoch 28/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.0608e-04 - val_accuracy: 0.6132 - val_loss: 3.7608\n",
      "Epoch 29/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.4357e-04 - val_accuracy: 0.6091 - val_loss: 3.8056\n",
      "Epoch 30/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.4412e-04 - val_accuracy: 0.6091 - val_loss: 3.8204\n",
      "Epoch 31/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.0056e-04 - val_accuracy: 0.6104 - val_loss: 3.8395\n",
      "Epoch 32/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.7951e-04 - val_accuracy: 0.6077 - val_loss: 3.8793\n",
      "Epoch 33/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.4035e-04 - val_accuracy: 0.6091 - val_loss: 3.8964\n",
      "Epoch 34/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.3426e-04 - val_accuracy: 0.6091 - val_loss: 3.9330\n",
      "Epoch 35/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.1816e-04 - val_accuracy: 0.6091 - val_loss: 3.9513\n",
      "Epoch 36/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.0238e-04 - val_accuracy: 0.6063 - val_loss: 3.9546\n",
      "Epoch 37/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.8669e-04 - val_accuracy: 0.6091 - val_loss: 3.9865\n",
      "Epoch 38/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.7650e-04 - val_accuracy: 0.6091 - val_loss: 4.0009\n",
      "Epoch 39/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.6736e-04 - val_accuracy: 0.6091 - val_loss: 4.0222\n",
      "Epoch 40/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.5099e-04 - val_accuracy: 0.6091 - val_loss: 4.0336\n",
      "Epoch 41/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.4366e-04 - val_accuracy: 0.6091 - val_loss: 4.0600\n",
      "Epoch 42/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.3254e-04 - val_accuracy: 0.6091 - val_loss: 4.0673\n",
      "Epoch 43/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.2917e-04 - val_accuracy: 0.6091 - val_loss: 4.0906\n",
      "Epoch 44/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.2986e-04 - val_accuracy: 0.6091 - val_loss: 4.1014\n",
      "Epoch 45/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.2421e-04 - val_accuracy: 0.6091 - val_loss: 4.1176\n",
      "Epoch 46/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.0484e-04 - val_accuracy: 0.6091 - val_loss: 4.1376\n",
      "Epoch 47/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.0201e-04 - val_accuracy: 0.6104 - val_loss: 4.1571\n",
      "Epoch 48/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 9.9012e-05 - val_accuracy: 0.6104 - val_loss: 4.1693\n",
      "Epoch 49/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.0333e-04 - val_accuracy: 0.6077 - val_loss: 4.1791\n",
      "Epoch 50/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 8.9920e-05 - val_accuracy: 0.6104 - val_loss: 4.2006\n",
      "Epoch 51/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 8.8006e-05 - val_accuracy: 0.6091 - val_loss: 4.2069\n",
      "Epoch 52/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 8.8532e-05 - val_accuracy: 0.6091 - val_loss: 4.2266\n",
      "Epoch 53/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.7809e-05 - val_accuracy: 0.6091 - val_loss: 4.2401\n",
      "Epoch 54/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 7.6764e-05 - val_accuracy: 0.6091 - val_loss: 4.2538\n",
      "Epoch 55/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.1295e-05 - val_accuracy: 0.6091 - val_loss: 4.2749\n",
      "Epoch 56/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.3001e-05 - val_accuracy: 0.6104 - val_loss: 4.2805\n",
      "Epoch 57/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 6.5165e-05 - val_accuracy: 0.6077 - val_loss: 4.2961\n",
      "Epoch 58/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 6.0387e-05 - val_accuracy: 0.6077 - val_loss: 4.3158\n",
      "Epoch 59/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 5.9606e-05 - val_accuracy: 0.6077 - val_loss: 4.3276\n",
      "Epoch 60/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 5.6363e-05 - val_accuracy: 0.6077 - val_loss: 4.3509\n",
      "Epoch 61/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.0888e-05 - val_accuracy: 0.6049 - val_loss: 4.3491\n",
      "Epoch 62/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 5.2541e-05 - val_accuracy: 0.6091 - val_loss: 4.3596\n",
      "Epoch 63/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 5.0569e-05 - val_accuracy: 0.6077 - val_loss: 4.3765\n",
      "Epoch 64/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 4.8336e-05 - val_accuracy: 0.6049 - val_loss: 4.3905\n",
      "Epoch 65/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 4.1517e-05 - val_accuracy: 0.6063 - val_loss: 4.4043\n",
      "Epoch 66/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 4.3427e-05 - val_accuracy: 0.6049 - val_loss: 4.4148\n",
      "Epoch 67/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.1950e-05 - val_accuracy: 0.6036 - val_loss: 4.4188\n",
      "Epoch 68/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 4.0254e-05 - val_accuracy: 0.6049 - val_loss: 4.4474\n",
      "Epoch 69/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.7983e-05 - val_accuracy: 0.6063 - val_loss: 4.4578\n",
      "Epoch 70/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.5183e-05 - val_accuracy: 0.6063 - val_loss: 4.4712\n",
      "Epoch 71/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.2383e-05 - val_accuracy: 0.6063 - val_loss: 4.4791\n",
      "Epoch 72/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.2232e-05 - val_accuracy: 0.6063 - val_loss: 4.4914\n",
      "Epoch 73/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1580e-05 - val_accuracy: 0.6036 - val_loss: 4.5014\n",
      "Epoch 74/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.0414e-05 - val_accuracy: 0.6049 - val_loss: 4.5172\n",
      "Epoch 75/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.9227e-05 - val_accuracy: 0.6036 - val_loss: 4.5256\n",
      "Epoch 76/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.7464e-05 - val_accuracy: 0.6104 - val_loss: 4.5424\n",
      "Epoch 77/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.7607e-05 - val_accuracy: 0.6036 - val_loss: 4.5550\n",
      "Epoch 78/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.4884e-05 - val_accuracy: 0.6063 - val_loss: 4.5701\n",
      "Epoch 79/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.3205e-05 - val_accuracy: 0.6104 - val_loss: 4.5779\n",
      "Epoch 80/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.0752e-05 - val_accuracy: 0.6036 - val_loss: 4.5920\n",
      "Epoch 81/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.1051e-05 - val_accuracy: 0.6091 - val_loss: 4.6068\n",
      "Epoch 82/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.1494e-05 - val_accuracy: 0.6077 - val_loss: 4.6125\n",
      "Epoch 83/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.0267e-05 - val_accuracy: 0.6091 - val_loss: 4.6162\n",
      "Epoch 84/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.8307e-05 - val_accuracy: 0.6104 - val_loss: 4.6430\n",
      "Epoch 85/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.6901e-05 - val_accuracy: 0.6063 - val_loss: 4.6548\n",
      "Epoch 86/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.8224e-05 - val_accuracy: 0.6091 - val_loss: 4.6578\n",
      "Epoch 87/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.6470e-05 - val_accuracy: 0.6091 - val_loss: 4.6814\n",
      "Epoch 88/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.6240e-05 - val_accuracy: 0.6132 - val_loss: 4.6905\n",
      "Epoch 89/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.5451e-05 - val_accuracy: 0.6091 - val_loss: 4.7074\n",
      "Epoch 90/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.4596e-05 - val_accuracy: 0.6077 - val_loss: 4.7219\n",
      "Epoch 91/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.5155e-05 - val_accuracy: 0.6091 - val_loss: 4.7200\n",
      "Epoch 92/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.3075e-05 - val_accuracy: 0.6091 - val_loss: 4.7268\n",
      "Epoch 93/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.3288e-05 - val_accuracy: 0.6077 - val_loss: 4.7485\n",
      "Epoch 94/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.2352e-05 - val_accuracy: 0.6091 - val_loss: 4.7698\n",
      "Epoch 95/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.0759e-05 - val_accuracy: 0.6077 - val_loss: 4.7687\n",
      "Epoch 96/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.1218e-05 - val_accuracy: 0.6077 - val_loss: 4.7855\n",
      "Epoch 97/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.0513e-05 - val_accuracy: 0.6077 - val_loss: 4.7937\n",
      "Epoch 98/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.0506e-05 - val_accuracy: 0.6077 - val_loss: 4.8099\n",
      "Epoch 99/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 9.6092e-06 - val_accuracy: 0.6104 - val_loss: 4.8203\n",
      "Epoch 100/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.8526e-06 - val_accuracy: 0.6104 - val_loss: 4.8295\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4816 - loss: 8.8441\n",
      "Test accuracy: 0.6104252338409424\n"
     ]
    }
   ],
   "source": [
    "# Get input shape and number of classes\n",
    "input_shape = X_train.shape[1:]  # shape of each input sample\n",
    "num_classes = len(np.unique(y_train))  # number of class labels\n",
    "\n",
    "# Create and train the CNN model\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
